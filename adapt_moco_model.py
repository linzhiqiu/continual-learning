import torch

import argparse

argparser = argparse.ArgumentParser()
argparser.add_argument('--model_path', default=None, type=str,
                       help='The model checkpoint file generated by moco/main_yfcc.py.')
argparser.add_argument('--save_path', default=None, type=str,
                       help='Path to save the state_dict (after removing the key prefix) ')

def get_state_dict(path):
    checkpoint = torch.load(path)
    state_dict = checkpoint['state_dict']
    for k in list(state_dict.keys()):
        # retain only encoder_q up to before the embedding layer
        if k.startswith('module.encoder_q') and not k.startswith('module.encoder_q.fc'):
            # remove prefix
            state_dict[k[len("module.encoder_q."):]] = state_dict[k]
        # delete renamed or unused k
        del state_dict[k]
    return state_dict

if __name__ == '__main__':
    args = argparser.parse_args()
    state_dict = get_state_dict(args.model_path)
    torch.save(state_dict, args.save_path)
    print(f"State dict file saved to {args.save_path}")