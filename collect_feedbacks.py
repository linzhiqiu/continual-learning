# For label verification
import sys
sys.path.append("./CLIP")
import os
import time
import shutil

from pathlib import Path
import argparse
from utils import load_json, save_as_json

argparser = argparse.ArgumentParser()
argparser.add_argument("--original_folder",
                       default="/data3/zhiqiul/clear_datasets/CLEAR10-TEST/", type=str,
                       help="Original folder generated by prepare_concepts.py")
argparser.add_argument("--new_folder",
                       default="/data3/zhiqiul/clear_datasets/CLEAR10-TEST-CLEANED/", type=str,
                       help="New folder to save")
argparser.add_argument("--cleaned_folder",
                       default="/data3/zhiqiul/clear_datasets/CMU_1_json_20220105", type=str,
                       help="Folder with feedback")
argparser.add_argument("--label_mapper",
                       default="/data3/zhiqiul/clear_datasets/CMU_1_json_20220105/label_map.json", type=str,
                       help="Map original labels to user-defined labels")
argparser.add_argument("--num_imgs",
                       default=150, type=int,
                       help="Number of images to save in clean folder")

def retrieve_cleaned_folder_labels(cleaned_folder, bucket_indices):
    user_label_set = set()
    for i, b_idx in enumerate(bucket_indices):
        cleaned_folder_i = cleaned_folder / b_idx
        assert cleaned_folder_i.exists()
        cleaned_folder_i_labels = list(cleaned_folder_i.glob('[!.]*/'))
        if i == 0:
            sorted_prompts = sorted([str(f)[len(str(cleaned_folder_i))+1:] for f in cleaned_folder_i_labels])
        else:
            new_sorted_prompts = sorted([str(f)[len(str(cleaned_folder_i))+1:] for f in cleaned_folder_i_labels])
            if not sorted_prompts == new_sorted_prompts:
                import pdb; pdb.set_trace()
        for label in sorted_prompts:
            cleaned_folder_i_label = cleaned_folder_i / label
            json_files = cleaned_folder_i_label.glob('*.json')
            for json_file in json_files:
                res = load_json(json_file)
                user_labels = res['task_result']['annotations'][0]['input']['value']
                for user_label in user_labels:
                    user_label_set.add(user_label)
    return list(user_label_set)

def retrieve_cleaned_folder_information(cleaned_folder, bucket_indices, num_imgs, label_mapper_dict):
    cleaned_dict = {
        'sorted_prompts' : [],
        'cleaned_images' : {},
    }
    for i, b_idx in enumerate(bucket_indices):
        cleaned_folder_i = cleaned_folder / b_idx
        assert cleaned_folder_i.exists()
        cleaned_folder_i_labels = list(cleaned_folder_i.glob('[!.]*/'))
        if i == 0:
            cleaned_dict['sorted_prompts'] = sorted([str(f)[len(str(cleaned_folder_i))+1:] for f in cleaned_folder_i_labels])
        else:
            assert cleaned_dict['sorted_prompts'] == sorted([str(f)[len(str(cleaned_folder_i))+1:] for f in cleaned_folder_i_labels])
        
        cleaned_dict['cleaned_images'][b_idx] = {}
        for label in cleaned_dict['sorted_prompts']:
            cleaned_dict['cleaned_images'][b_idx][label] = [] # list of flickr ID
            cleaned_folder_i_label = cleaned_folder_i / label
            json_files = cleaned_folder_i_label.glob('*.json')
            for json_file in json_files:
                ID = str(json_file)[len(str(cleaned_folder_i_label))+1:-5]
                res = load_json(json_file)
                user_labels = [label_mapper_dict[k] for k in res['task_result']['annotations'][0]['input']['value']]
                if len(user_labels) == 1 and user_labels[0] == label:
                    if len(cleaned_dict['cleaned_images'][b_idx][label]) < num_imgs:
                        cleaned_dict['cleaned_images'][b_idx][label].append(ID)
            if len(cleaned_dict['cleaned_images'][b_idx][label]) < num_imgs:
                print(f"Not enough images for bucket {b_idx} label {label}")
                import pdb; pdb.set_trace()
    return cleaned_dict           

if __name__ == '__main__':
    args = argparser.parse_args()
    
    # First verify original folder is consistent (have all buckets for all folders)
    original_folder = Path(args.original_folder)
    assert original_folder.exists(), "Original folder does not exist"
    
    concept_group_dict_path = original_folder / 'concept_group_dict.json'
    class_names_path = original_folder / 'class_names.txt'
    filelists_json_path = original_folder / 'filelists.json'
    filelists_path = original_folder / 'filelists'
    labeled_images_path = original_folder / 'labeled_images'
    labeled_metadata_json_path = original_folder / 'labeled_metadata.json'
    labeled_metadata_path = original_folder / 'labeled_metadata'
    
    original_filelists = load_json(filelists_json_path)
    original_labeled_metadata = load_json(labeled_metadata_json_path)
    assert sorted(list(original_filelists.keys())) == sorted(list(original_labeled_metadata.keys()))
    bucket_indices = sorted(list(original_filelists.keys()), key=lambda idx: int(idx))
    
    # assert all buckets exists in cleaned folder
    cleaned_folder = Path(args.cleaned_folder)
    assert cleaned_folder.exists(), "Cleaned folder does not exist"
    
    label_mapper = Path(args.label_mapper)
    if not label_mapper.exists():
        print(f"Please specify a label map at {label_mapper}")
        print(f"Here are all user-named labels for reference: ")
        print(retrieve_cleaned_folder_labels(cleaned_folder, bucket_indices))
        exit(0)
    else:
        label_mapper_dict = load_json(label_mapper)
    
    cleaned_dict = retrieve_cleaned_folder_information(cleaned_folder, bucket_indices, args.num_imgs, label_mapper_dict)

    new_folder = Path(args.new_folder)
    new_folder.mkdir(exist_ok=True)
    
    # sorted_prompts = class_names_path.read_text().split("\n")
    
    new_filelists_path = new_folder / 'filelists'
    new_filelists_path.mkdir(exist_ok=True)

    new_labeled_images_path = new_folder / 'labeled_images'
    new_labeled_images_path.mkdir(exist_ok=True)

    new_labeled_metadata_path = new_folder / 'labeled_metadata'
    new_labeled_metadata_path.mkdir(exist_ok=True)

    new_concept_group_dict_path = new_folder / 'concept_group_dict.json'
    shutil.copy(concept_group_dict_path, new_concept_group_dict_path)
    
    new_class_names_path = new_folder / "class_names.txt"
    new_class_names_str = "\n".join(cleaned_dict['sorted_prompts'])
    if new_class_names_path.exists():
        old_class_names_str = new_class_names_path.read_text()
        if not new_class_names_str == old_class_names_str:
            raise ValueError(f"Old class names do not match with current")
    else:
        with open(new_class_names_path, 'w+') as f:
            f.write(new_class_names_str)
    
    new_labeled_metadata_dict = {}
    new_filelists_dict = {}
    for b_idx in bucket_indices:
        labeled_metadata_path_i = labeled_metadata_path / b_idx
        assert labeled_metadata_path_i.exists()
        new_labeled_metadata_path_i = new_labeled_metadata_path / b_idx
        new_labeled_metadata_path_i.mkdir(exist_ok=True)
        
        new_labeled_metadata_dict[b_idx] = str(new_labeled_metadata_path_i)

        labeled_images_path_i = labeled_images_path / b_idx
        assert labeled_images_path_i.exists()
        new_labeled_images_path_i = new_labeled_images_path / b_idx
        new_labeled_images_path_i.mkdir(exist_ok=True)
        
        new_filelists_path_i = new_filelists_path / (b_idx + ".txt")
        new_filelists_dict[b_idx] = str(new_filelists_path_i)
        
        new_filelist_strs_list_i = []

        for label in cleaned_dict['cleaned_images'][b_idx]:
            label_index = cleaned_dict['sorted_prompts'].index(label)
            new_labeled_images_path_i_label = new_labeled_images_path_i / label
            new_labeled_images_path_i_label.mkdir(exist_ok=True)

            new_labeled_metadata_path_i_label = new_labeled_metadata_path_i / (label + ".json")
            new_labeled_metadata_i_label = {} # key is flickr ID (str), value is metadata dict for this image
            
            labeled_metadata_path_i_label = labeled_metadata_path_i / (label + ".json")
            labeled_metadata_i_label = load_json(labeled_metadata_path_i_label) # key is flickr ID (str), value is metadata dict for this image
            
            ID_list = cleaned_dict['cleaned_images'][b_idx][label]
            for ID in ID_list:
                if not ID in labeled_metadata_i_label:
                    raise ValueError(f"{ID} not in original metadata dict")
                meta = labeled_metadata_i_label[ID]
                
                original_path = original_folder / meta['IMG_PATH']
                if not original_path.exists():
                    raise FileNotFoundError(f"{original_path} not found")
                assert ID == meta['ID']
                EXT = meta['EXT']
                img_name = f"{ID}.{EXT}"
                transfer_path = new_labeled_images_path_i_label / img_name
                shutil.copy(original_path, transfer_path)
                meta['IMG_DIR'] = str(new_folder)
                meta['IMG_PATH'] = str(Path("labeled_images") / b_idx / label / img_name)
                new_labeled_metadata_i_label[ID] = meta
                new_filelist_strs_list_i.append(f"{meta['IMG_PATH']} {label_index}")

            save_as_json(new_labeled_metadata_path_i_label, new_labeled_metadata_i_label)
        filelist_str = "\n".join(new_filelist_strs_list_i)
        with open(new_filelists_path_i, "w+") as f:
            f.write(filelist_str)
            
    save_as_json(new_filelists_json_path, new_filelists_dict)
    save_as_json(new_labeled_metadata_json_path, new_labeled_metadata_dict)

    # optional folders. If exist, then copy all of them
    all_images_path = original_folder / 'all_images'
    all_metadata_path = original_folder / 'all_metadata'
    
    new_all_images_path = new_folder / 'all_images'
    new_all_metadata_path = new_folder / 'all_metadata'
    new_all_metadata_json_path = new_folder / 'all_metadata.json'
    
    if all_images_path.exists():
        shutil.copytree(all_images_path, new_all_images_path)
    
    if all_metadata_path.exists():
        new_all_metadata_dict = {}
        new_all_metadata_path.mkdir(exist_ok=True)
        for b_idx in bucket_indices:
            all_metadata_path_i = all_metadata_path / (b_idx + ".json")
            all_metadata_i = load_json(all_metadata_path_i) # key is flickr ID, value is metadata dict

            new_all_metadata_path_i = new_all_metadata_path / (b_idx + ".json")
            new_all_metadata_dict[b_idx] = str(new_all_metadata_path_i)
            new_all_metadata_i = {} # key is flickr ID, value is metadata dict

            for ID in all_metadata_i:
                meta = all_metadata_i[ID]
                meta['IMG_DIR'] = str(new_folder)
                new_all_metadata_i[ID] = meta

            save_as_json(new_all_metadata_path_i, new_all_metadata_i)
        save_as_json(new_all_metadata_json_path, new_all_metadata_dict)