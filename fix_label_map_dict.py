from utils import load_json, save_as_json
import argparse
import random
import torch
from pathlib import Path
import shutil

argparser = argparse.ArgumentParser()
argparser.add_argument("--folder_path",
                       default='/data3/zhiqiul/clear_datasets/CLEAR10-TEST-BACKUP',
                    #    default='/data3/zhiqiul/clear_datasets/CLEAR10-TEST',
                    #    default='/data3/zhiqiul/clear_datasets/CLEAR10-TEST-CLEANED',
                    #    default='/data3/zhiqiul/clear_datasets/CLEAR100-V0',
                    #    default='/data3/zhiqiul/clear_datasets/CLEAR50-V2',
                    #    default='/data3/zhiqiul/CLEAR-10-PUBLIC',
                       help="The folder generated by prepare_concepts.py (containing labeled_metadata.json, etc.)")
argparser.add_argument("--label_map_dict",
                       default=None, type=str,
                       help="If the prompts are too long (like containing space and comma), you can provide a dictionary mapping the prompt to a shorter label name")


if __name__ == '__main__':
    args = argparser.parse_args()

    folder_path = Path(args.folder_path)
    assert folder_path.exists(), f"{folder_path} does not exist"
    
    label_map_dict_path = Path(args.label_map_dict)
    if label_map_dict_path.exists():
        print("Use a label_map_dict to shorten label names")
        label_map_dict = load_json(label_map_dict_path)
        saved_label_map_dict_path = folder_path / "label_map_dict.json"
        save_as_json(saved_label_map_dict_path, label_map_dict)
    else:
        print("No label_map_dict is given.")
        exit(0)

    class_names_path = folder_path / 'class_names.txt'
    shutil.copy(class_names_path, folder_path / 'prompt_names.txt')
    
    class_names_str = class_names_path.read_text()
    old_sorted_prompts = class_names_str.split("\n") # class index determined by this list

    sorted_prompts = [label_map_dict[k] for k in old_sorted_prompts]
    sorted_list = sorted([(k, name) for k, name in enumerate(sorted_prompts)], key=lambda x: x[1])
    old_to_new_index = {k : i for i, (k, _) in enumerate(sorted_list)}
    sorted_prompts = sorted(sorted_prompts)

    labeled_metadata_path = folder_path / 'labeled_metadata'
    labeled_metadata_json_path = folder_path / 'labeled_metadata.json'
    labeled_metadata = load_json(labeled_metadata_json_path)
    bucket_indices = sorted(list(labeled_metadata.keys()), key = lambda x : int(x))
    labeled_images_path = folder_path / 'labeled_images'
    assert labeled_images_path.exists()

    for b_idx in bucket_indices:
        labeled_metadata_path_i = labeled_metadata_path / b_idx
        assert labeled_metadata_path_i.exists()
        labeled_images_path_i = labeled_images_path / b_idx
        assert labeled_images_path_i.exists()
        # import pdb; pdb.set_trace()
        for label in list(labeled_metadata[b_idx].keys()):
            # try:
            new_label = label_map_dict[label]
            # except:
            #     import pdb; pdb.set_trace()

            labeled_images_path_i_label = labeled_images_path_i / label
            if labeled_images_path_i_label.exists():
                labeled_images_path_i_new_label = labeled_images_path_i / new_label
                labeled_images_path_i_label.rename(labeled_images_path_i_new_label)
                print(f"renaming {labeled_images_path_i_label} to {labeled_images_path_i_new_label}")
            
            labeled_metadata_path_i_label = labeled_metadata_path_i / (label + ".json")
            labeled_metadata_path_i_new_label = labeled_metadata_path_i / (new_label + ".json")
            del labeled_metadata[b_idx][label]
            labeled_metadata[b_idx][new_label] = str(Path('labeled_metadata') / b_idx / (new_label + ".json"))
            if labeled_metadata_path_i_label.exists():
                labeled_metadata_i_label = load_json(labeled_metadata_path_i_label) # key is flickr ID (str), value is metadata dict for this image
                labeled_metadata_path_i_label.unlink(missing_ok=False)
                for ID in labeled_metadata_i_label:
                    meta = labeled_metadata_i_label[ID]
                    ID = meta['ID']
                    EXT = meta['EXT']
                    img_name = f"{ID}.{EXT}"
                    meta['IMG_PATH'] = str(Path("labeled_images") / b_idx / new_label / img_name)

                save_as_json(labeled_metadata_path_i_new_label, labeled_metadata_i_label)
    
    save_as_json(labeled_metadata_json_path, labeled_metadata)

    for name in ['byol_imagenet', 'moco_imagenet', 'imagenet', 'moco_b0']:
        features_path = folder_path / 'features'
        assert features_path.exists()
        features_name_path = features_path / name
        assert features_name_path.exists()
        features_dict_path = features_name_path / 'features.json'
        features_dict = load_json(features_dict_path)
        
        for b_idx in bucket_indices:
            features_path_i = features_name_path / b_idx
            assert features_path_i.exists()
            
            for label in list(features_dict[b_idx].keys()):
                new_label = label_map_dict[label]

                features_path_i_label = features_path_i / (label + ".pth")
                features_path_i_new_label = features_path_i / (new_label + ".pth")
                del features_dict[b_idx][label]
                features_dict[b_idx][new_label] = str(Path('features') / Path(name) / b_idx / (new_label + ".pth"))
                if features_path_i_label.exists():
                    features_i_label = torch.load(features_path_i_label)
                    features_path_i_label.unlink()
                    print(f"{features_path_i_label} save to {features_path_i_new_label}")
                    torch.save(features_i_label, features_path_i_new_label)
        save_as_json(features_dict_path, features_dict)
        print(f"Feature information saved to {features_dict_path}")
    
    class_names_str = "\n".join(sorted_prompts)
    with open(class_names_path, 'w+') as f:
        f.write(class_names_str)

