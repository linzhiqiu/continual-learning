from utils import load_json, save_as_json
import argparse
from tqdm import tqdm
import torch
import os
from pathlib import Path
import torchvision.transforms as transforms
import torchvision.models as models
from torchvision.datasets.folder import default_loader
import shutil

device = "cuda" if torch.cuda.is_available() else "cpu"

argparser = argparse.ArgumentParser()
argparser.add_argument("--folder_path",
                       default='/data3/zhiqiul/clear_datasets/CLEAR10-TEST',
                       help="The folder generated by prepare_concepts.py (containing labeled_metadata.json, etc.)")
argparser.add_argument("--name",
                       default='default', type=str,
                       help="Please name this model. Features will be saved under {args.folder_path}/features/{args.name}")
argparser.add_argument("--state_dict_path",
                       type=str,
                       help="Specify the path of this pre-trained model state_dict.")
argparser.add_argument("--arch",
                       type=str, default='resnet50',
                       help="Specify the architecture here.")

class SimpleDataset(torch.utils.data.Dataset):
    def __init__(self, samples, transform):
        self.samples = samples
        self.transform = transform
    
    def __len__(self):
        return len(self.samples)
    
    def __getitem__(self,index):
        path, ID = self.samples[index]
        sample = default_loader(path)
        sample = self.transform(sample)
        return sample, ID

def extract_features_dict(model, transform, paths_and_IDs_list):
    model.to(device)
    loader = torch.utils.data.DataLoader(
        SimpleDataset(paths_and_IDs_list,transform),
        shuffle=False,
        batch_size=10,
        num_workers=4,
    )
    features_dict = {}
    with torch.no_grad():
        for inputs, IDs in tqdm(loader):
            inputs = inputs.cuda()
            outputs = model(inputs)
            for output, ID in zip(outputs, IDs):
                features_dict[ID] = output.cpu()
    return features_dict

if __name__ == '__main__':
    args = argparser.parse_args()

    folder_path = Path(args.folder_path)
    assert folder_path.exists(), f"{folder_path} does not exist"

    class_names_path = folder_path / 'class_names.txt'
    class_names_str = class_names_path.read_text()
    sorted_prompts = class_names_str.split("\n")

    labeled_images_path = folder_path / 'labeled_images'
    assert labeled_images_path.exists()

    labeled_metadata_json_path = folder_path / 'labeled_metadata.json'
    labeled_metadata = load_json(labeled_metadata_json_path)
    bucket_indices = sorted(list(labeled_metadata.keys()), key = lambda x : int(x))

    features_path = folder_path / 'features'
    features_path.mkdir(exist_ok=True)
    features_name_path = features_path / args.name
    features_name_path.mkdir(exist_ok=True)
    features_dict_path = features_name_path / 'features.json'
    state_dict_save_path = features_name_path / f'state_dict.pth.tar'
    features_dict = {} # features_dict[bucket_index] = path to features dictionary
    
    normalize = transforms.Normalize(mean=[0.485, 0.456, 0.406],
                                     std=[0.229, 0.224, 0.225])
    test_transform = transforms.Compose([
        transforms.Resize(224),
        transforms.CenterCrop(224),
        transforms.ToTensor(),
        normalize,
    ])
    
    print("=> using arch '{}'".format(args.arch))
    model = models.__dict__[args.arch](pretrained=False)
    
    shutil.copy(args.state_dict_path, state_dict_save_path)
    print(f"Copied {args.state_dict_path} to {state_dict_save_path}")
    state_dict = torch.load(args.state_dict_path)
    model.fc = torch.nn.Identity()
    model.load_state_dict(state_dict)
    for p in model.parameters():
        p.requires_grad = False
    model.eval()

    for b_idx in bucket_indices:
        print(f"Working on {b_idx}")
        features_path_i = features_name_path / b_idx
        features_path_i.mkdir(exist_ok=True)
        features_dict[b_idx] = {} # key is label, value is dict
        
        for label in labeled_metadata[b_idx]:
            features_path_i_label = features_path_i / (label + ".pth")
            features_dict[b_idx][label] = str(Path("features") / b_idx / (label + ".pth"))
            paths_i_label = [] # list of 2 element tuple. first element is image path, second element is ID

            labeled_metadata_path_i_label = labeled_metadata[b_idx][label]
            labeled_metadata_i_label = load_json(folder_path / labeled_metadata_path_i_label)
            for ID in labeled_metadata_i_label:
                path = Path(args.folder_path) / labeled_metadata_i_label[ID]['IMG_PATH']
                paths_i_label.append([path, ID])
            
            features_i_label = extract_features_dict(model, test_transform, paths_i_label) # key is flickr ID (str), value is tensor feature
            torch.save(features_i_label, features_path_i_label)
    save_as_json(features_dict_path, features_dict)
    print(f"Feature information saved to {features_dict_path}")
    