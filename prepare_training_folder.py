from utils import load_json, save_as_json
import argparse
import random
import torch
from pathlib import Path

argparser = argparse.ArgumentParser()
argparser.add_argument("--folder_path",
                       default='/data3/zhiqiul/clear_datasets/CLEAR10-TEST',
                       help="The folder generated by prepare_concepts.py (containing labeled_metadata.json, etc.)")
argparser.add_argument("--testset_ratio",
                       default=0., type=float,
                       help="If testset_ratio is 0.0, then all data will be used for training " \
                            "(resulting folder will be saved under a subfolder named 'all', " \
                            "and seed will be ignored). Otherwise, args.testset_ratio data " \
                            "will be used for testing, and the rest for training (resulting " \
                            "folder will be saved under 'testset_ratio_{args.testset_ratio}/seed_{args.seed}').")
argparser.add_argument("--seed",
                       type=int, default=0,
                       help="Seed for random split.")

if __name__ == '__main__':
    args = argparser.parse_args()

    folder_path = Path(args.folder_path)
    assert folder_path.exists(), f"{folder_path} does not exist"

    perform_random_split = False
    if args.testset_ratio == 0.:
        print("No train/test split")
        split_name = 'all'
        training_folder_path = folder_path / 'training_folder' / split_name
    elif args.testset_ratio < 1.0:
        print("Make a train/test split")
        perform_random_split = True
        split_name = f'testset_ratio_{args.testset_ratio}'
        seed_name = f"seed_{args.seed}"
        random.seed(args.seed)
        training_folder_path = folder_path / 'training_folder' / split_name / seed_name
    
    training_folder_path.mkdir(exist_ok=True, parents=True)

    class_names_path = folder_path / 'class_names.txt'
    class_names_str = class_names_path.read_text()
    sorted_prompts = class_names_str.split("\n") # class index determined by this list

    labeled_images_path = folder_path / 'labeled_images'
    assert labeled_images_path.exists()

    labeled_metadata_json_path = folder_path / 'labeled_metadata.json'
    labeled_metadata = load_json(labeled_metadata_json_path)
    bucket_indices = sorted(list(labeled_metadata.keys()), key = lambda x : int(x))

    features_path = folder_path / 'features'
    features_to_transfer = {} # key is feature type (str), value is 
    if features_path.exists():
        for features_subpath in features_path.glob("*/"):
            feature_type = features_subpath.name
            features_dict_path = features_subpath / 'features.json'
            features_dict = load_json(features_dict_path)
            features_to_transfer[feature_type] = features_dict
            
    training_folder_path_filelist = training_folder_path / f'filelists'
    training_folder_path_filelist.mkdir(exist_ok=True)
    training_folder_path_features = training_folder_path / f'features'
    training_folder_path_features.mkdir(exist_ok=True)
    for feature_type in features_to_transfer:
        training_folder_path_feature_type = training_folder_path_features / feature_type
        training_folder_path_feature_type.mkdir(exist_ok=True)

    bucket_indices_path = training_folder_path / f'bucket_indices.json'
    save_as_json(bucket_indices_path, bucket_indices)

    for b_idx in bucket_indices:
        print(f"Working on {b_idx}")
        all_images_b_idx = [] # each element is a tuple of (class_index, img_path)
        all_features_b_idx = {feature_type : [] for feature_type in features_to_transfer} # key is feature_type, value is a list of tuples of (class_index, feature_tensor)
        
        for label in labeled_metadata[b_idx]:
            class_index = sorted_prompts.index(label)

            labeled_metadata_path_i_label = labeled_metadata[b_idx][label]
            labeled_metadata_i_label = load_json(folder_path / labeled_metadata_path_i_label)
            feature_tensor_label = torch.load(folder_path / features_to_transfer[feature_type][b_idx][label])
            for ID in labeled_metadata_i_label:
                all_images_b_idx.append((class_index, labeled_metadata_i_label[ID]['IMG_PATH']))
                for feature_type in features_to_transfer:
                    feature_tensor = feature_tensor_label[ID]
                    all_features_b_idx[feature_type].append((class_index, feature_tensor))

        
        all_filelist_strs = []
        for class_index, path in all_images_b_idx:
            all_filelist_strs.append(f"{path} {class_index}")

        all_feature_tensors_dict = {}
        for feature_type in all_features_b_idx:
            all_feature_tensors_of_type = torch.cat(
                                              [tensor
                                               for _, tensor in all_features_b_idx[feature_type]]
                                          )
            all_class_index = [class_index for class_index, _ in all_features_b_idx[feature_type]]
            all_feature_tensors_dict[feature_type] = (all_feature_tensors_of_type, all_class_index)

        filelist_str = "\n".join(all_filelist_strs)
        training_folder_path_filelist_b_idx = training_folder_path_filelist / b_idx
        training_folder_path_filelist_b_idx.mkdir(exist_ok=True)
        
        training_folder_path_filelist_b_idx_all_path = training_folder_path_filelist_b_idx / "all.txt"
        with open(training_folder_path_filelist_b_idx_all_path, "w+") as f:
            f.write(filelist_str)

        for feature_type in all_feature_tensors_dict:
            training_folder_path_feature_type_b_idx = training_folder_path_features / feature_type / b_idx
            training_folder_path_feature_type_b_idx.mkdir(exist_ok=True)
            training_folder_path_feature_type_b_idx_all_path = training_folder_path_feature_type_b_idx / "all.pth"
            torch.save(all_feature_tensors_dict[feature_type], training_folder_path_feature_type_b_idx_all_path)

        if perform_random_split:
            num_images = len(all_images_b_idx)
            num_test_images = int(num_images * args.testset_ratio)
            num_train_images = num_images - num_test_images
            
            shuffled_indices = list(range(num_images))
            random.shuffle(shuffled_indices)
            train_indices = shuffled_indices[:num_train_images]
            test_indices = shuffled_indices[num_train_images:]

            train_filelist_strs = [all_filelist_strs[i] for i in train_indices]
            filelist_str_train = "\n".join(train_filelist_strs)
            training_folder_path_filelist_b_idx_train_path = training_folder_path_filelist_b_idx / "train.txt"
            with open(training_folder_path_filelist_b_idx_train_path, "w+") as f:
                f.write(filelist_str_train)

            test_filelist_strs = [all_filelist_strs[i] for i in test_indices]
            filelist_str_test = "\n".join(test_filelist_strs)
            training_folder_path_filelist_b_idx_test_path = training_folder_path_filelist_b_idx / "test.txt"
            with open(training_folder_path_filelist_b_idx_test_path, "w+") as f:
                f.write(filelist_str_test)

            for feature_type in all_feature_tensors_dict:
                all_tensors, all_classes = all_feature_tensors_dict[feature_type]
                
                training_folder_path_feature_type_b_idx = training_folder_path_features / feature_type / b_idx
                
                training_folder_path_feature_type_b_idx_train_path = training_folder_path_feature_type_b_idx / "train.pth"
                train_indices_tensor = torch.LongTensor(train_indices)
                train_tensors = torch.index_select(all_tensors, 0, train_indices_tensor)
                train_classes = [all_classes[i] for i in train_indices]
                torch.save((train_tensors, train_classes),  training_folder_path_feature_type_b_idx_train_path)

                training_folder_path_feature_type_b_idx_test_path = training_folder_path_feature_type_b_idx / "test.pth"
                test_indices_tensor = torch.LongTensor(test_indices)
                test_tensors = torch.index_select(all_tensors, 0, test_indices_tensor)
                test_classes = [all_classes[i] for i in test_indices]
                torch.save((test_tensors, test_classes),  training_folder_path_feature_type_b_idx_test_path)
                
                

